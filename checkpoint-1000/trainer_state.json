{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.5974025974025974,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 4.995670995670996e-05,
      "loss": 11.2877,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.987012987012987e-05,
      "loss": 9.8649,
      "step": 4
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.978354978354979e-05,
      "loss": 5.4566,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.9696969696969694e-05,
      "loss": 3.8767,
      "step": 8
    },
    {
      "epoch": 0.03,
      "learning_rate": 4.961038961038961e-05,
      "loss": 2.8,
      "step": 10
    },
    {
      "epoch": 0.03,
      "learning_rate": 4.9523809523809525e-05,
      "loss": 2.1341,
      "step": 12
    },
    {
      "epoch": 0.04,
      "learning_rate": 4.9437229437229437e-05,
      "loss": 2.2775,
      "step": 14
    },
    {
      "epoch": 0.04,
      "learning_rate": 4.93939393939394e-05,
      "loss": 2.1819,
      "step": 16
    },
    {
      "epoch": 0.05,
      "learning_rate": 4.9307359307359304e-05,
      "loss": 1.888,
      "step": 18
    },
    {
      "epoch": 0.05,
      "learning_rate": 4.922077922077922e-05,
      "loss": 2.0898,
      "step": 20
    },
    {
      "epoch": 0.06,
      "learning_rate": 4.9134199134199135e-05,
      "loss": 1.837,
      "step": 22
    },
    {
      "epoch": 0.06,
      "learning_rate": 4.904761904761905e-05,
      "loss": 1.4063,
      "step": 24
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.8961038961038966e-05,
      "loss": 2.2046,
      "step": 26
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.887445887445888e-05,
      "loss": 1.2981,
      "step": 28
    },
    {
      "epoch": 0.08,
      "learning_rate": 4.878787878787879e-05,
      "loss": 2.1617,
      "step": 30
    },
    {
      "epoch": 0.08,
      "learning_rate": 4.87012987012987e-05,
      "loss": 1.4914,
      "step": 32
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.861471861471862e-05,
      "loss": 1.5102,
      "step": 34
    },
    {
      "epoch": 0.09,
      "learning_rate": 4.8528138528138525e-05,
      "loss": 1.0972,
      "step": 36
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.8441558441558444e-05,
      "loss": 1.3975,
      "step": 38
    },
    {
      "epoch": 0.1,
      "learning_rate": 4.8354978354978356e-05,
      "loss": 1.7032,
      "step": 40
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.826839826839827e-05,
      "loss": 1.2901,
      "step": 42
    },
    {
      "epoch": 0.11,
      "learning_rate": 4.8181818181818186e-05,
      "loss": 0.981,
      "step": 44
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.80952380952381e-05,
      "loss": 1.3701,
      "step": 46
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.800865800865801e-05,
      "loss": 1.6635,
      "step": 48
    },
    {
      "epoch": 0.13,
      "learning_rate": 4.792207792207792e-05,
      "loss": 1.1614,
      "step": 50
    },
    {
      "epoch": 0.14,
      "learning_rate": 4.783549783549784e-05,
      "loss": 1.4515,
      "step": 52
    },
    {
      "epoch": 0.14,
      "learning_rate": 4.7748917748917746e-05,
      "loss": 1.401,
      "step": 54
    },
    {
      "epoch": 0.15,
      "learning_rate": 4.7662337662337664e-05,
      "loss": 1.4035,
      "step": 56
    },
    {
      "epoch": 0.15,
      "learning_rate": 4.7575757575757576e-05,
      "loss": 1.6931,
      "step": 58
    },
    {
      "epoch": 0.16,
      "learning_rate": 4.748917748917749e-05,
      "loss": 1.5432,
      "step": 60
    },
    {
      "epoch": 0.16,
      "learning_rate": 4.740259740259741e-05,
      "loss": 1.4209,
      "step": 62
    },
    {
      "epoch": 0.17,
      "learning_rate": 4.731601731601732e-05,
      "loss": 1.3215,
      "step": 64
    },
    {
      "epoch": 0.17,
      "learning_rate": 4.722943722943723e-05,
      "loss": 1.3313,
      "step": 66
    },
    {
      "epoch": 0.18,
      "learning_rate": 4.714285714285714e-05,
      "loss": 1.58,
      "step": 68
    },
    {
      "epoch": 0.18,
      "learning_rate": 4.705627705627706e-05,
      "loss": 1.5635,
      "step": 70
    },
    {
      "epoch": 0.19,
      "learning_rate": 4.696969696969697e-05,
      "loss": 2.5054,
      "step": 72
    },
    {
      "epoch": 0.19,
      "learning_rate": 4.6883116883116885e-05,
      "loss": 1.2684,
      "step": 74
    },
    {
      "epoch": 0.2,
      "learning_rate": 4.67965367965368e-05,
      "loss": 1.6366,
      "step": 76
    },
    {
      "epoch": 0.2,
      "learning_rate": 4.6709956709956716e-05,
      "loss": 1.4881,
      "step": 78
    },
    {
      "epoch": 0.21,
      "learning_rate": 4.662337662337663e-05,
      "loss": 1.1336,
      "step": 80
    },
    {
      "epoch": 0.21,
      "learning_rate": 4.653679653679654e-05,
      "loss": 1.7863,
      "step": 82
    },
    {
      "epoch": 0.22,
      "learning_rate": 4.645021645021646e-05,
      "loss": 1.3298,
      "step": 84
    },
    {
      "epoch": 0.22,
      "learning_rate": 4.636363636363636e-05,
      "loss": 1.1025,
      "step": 86
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.627705627705628e-05,
      "loss": 1.8774,
      "step": 88
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.6190476190476194e-05,
      "loss": 1.5597,
      "step": 90
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.6103896103896106e-05,
      "loss": 1.6556,
      "step": 92
    },
    {
      "epoch": 0.24,
      "learning_rate": 4.601731601731602e-05,
      "loss": 1.0998,
      "step": 94
    },
    {
      "epoch": 0.25,
      "learning_rate": 4.5930735930735936e-05,
      "loss": 0.9353,
      "step": 96
    },
    {
      "epoch": 0.25,
      "learning_rate": 4.584415584415585e-05,
      "loss": 1.3526,
      "step": 98
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.575757575757576e-05,
      "loss": 1.164,
      "step": 100
    },
    {
      "epoch": 0.26,
      "learning_rate": 4.567099567099568e-05,
      "loss": 2.1085,
      "step": 102
    },
    {
      "epoch": 0.27,
      "learning_rate": 4.562770562770563e-05,
      "loss": 1.9771,
      "step": 104
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.554112554112555e-05,
      "loss": 1.8428,
      "step": 106
    },
    {
      "epoch": 0.28,
      "learning_rate": 4.545454545454546e-05,
      "loss": 1.07,
      "step": 108
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.536796536796537e-05,
      "loss": 2.1348,
      "step": 110
    },
    {
      "epoch": 0.29,
      "learning_rate": 4.528138528138528e-05,
      "loss": 1.069,
      "step": 112
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.5194805194805194e-05,
      "loss": 1.2331,
      "step": 114
    },
    {
      "epoch": 0.3,
      "learning_rate": 4.510822510822511e-05,
      "loss": 1.2424,
      "step": 116
    },
    {
      "epoch": 0.31,
      "learning_rate": 4.5021645021645025e-05,
      "loss": 1.5527,
      "step": 118
    },
    {
      "epoch": 0.31,
      "learning_rate": 4.493506493506494e-05,
      "loss": 1.5643,
      "step": 120
    },
    {
      "epoch": 0.32,
      "learning_rate": 4.484848484848485e-05,
      "loss": 1.291,
      "step": 122
    },
    {
      "epoch": 0.32,
      "learning_rate": 4.476190476190477e-05,
      "loss": 1.0867,
      "step": 124
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.467532467532467e-05,
      "loss": 0.9701,
      "step": 126
    },
    {
      "epoch": 0.33,
      "learning_rate": 4.458874458874459e-05,
      "loss": 1.188,
      "step": 128
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.45021645021645e-05,
      "loss": 1.4153,
      "step": 130
    },
    {
      "epoch": 0.34,
      "learning_rate": 4.4415584415584415e-05,
      "loss": 1.5439,
      "step": 132
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.4329004329004334e-05,
      "loss": 1.1325,
      "step": 134
    },
    {
      "epoch": 0.35,
      "learning_rate": 4.4242424242424246e-05,
      "loss": 1.1811,
      "step": 136
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.415584415584416e-05,
      "loss": 1.3529,
      "step": 138
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.406926406926407e-05,
      "loss": 1.3931,
      "step": 140
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.398268398268399e-05,
      "loss": 0.9864,
      "step": 142
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.389610389610389e-05,
      "loss": 1.1301,
      "step": 144
    },
    {
      "epoch": 0.38,
      "learning_rate": 4.380952380952381e-05,
      "loss": 1.0795,
      "step": 146
    },
    {
      "epoch": 0.38,
      "learning_rate": 4.3722943722943724e-05,
      "loss": 0.9192,
      "step": 148
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.7815,
      "step": 150
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.3549783549783554e-05,
      "loss": 1.0015,
      "step": 152
    },
    {
      "epoch": 0.4,
      "learning_rate": 4.3463203463203466e-05,
      "loss": 0.8164,
      "step": 154
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.337662337662338e-05,
      "loss": 1.134,
      "step": 156
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.329004329004329e-05,
      "loss": 1.2445,
      "step": 158
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.320346320346321e-05,
      "loss": 1.4112,
      "step": 160
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.3116883116883114e-05,
      "loss": 0.7841,
      "step": 162
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.303030303030303e-05,
      "loss": 1.3765,
      "step": 164
    },
    {
      "epoch": 0.43,
      "learning_rate": 4.2943722943722944e-05,
      "loss": 1.174,
      "step": 166
    },
    {
      "epoch": 0.44,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 1.2845,
      "step": 168
    },
    {
      "epoch": 0.44,
      "learning_rate": 4.2770562770562775e-05,
      "loss": 1.5339,
      "step": 170
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.268398268398269e-05,
      "loss": 0.867,
      "step": 172
    },
    {
      "epoch": 0.45,
      "learning_rate": 4.25974025974026e-05,
      "loss": 1.948,
      "step": 174
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.251082251082251e-05,
      "loss": 0.9658,
      "step": 176
    },
    {
      "epoch": 0.46,
      "learning_rate": 4.242424242424243e-05,
      "loss": 1.2866,
      "step": 178
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.2337662337662334e-05,
      "loss": 1.7182,
      "step": 180
    },
    {
      "epoch": 0.47,
      "learning_rate": 4.225108225108225e-05,
      "loss": 1.2293,
      "step": 182
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.2164502164502165e-05,
      "loss": 1.5673,
      "step": 184
    },
    {
      "epoch": 0.48,
      "learning_rate": 4.207792207792208e-05,
      "loss": 1.1303,
      "step": 186
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.1991341991341996e-05,
      "loss": 1.4718,
      "step": 188
    },
    {
      "epoch": 0.49,
      "learning_rate": 4.190476190476191e-05,
      "loss": 1.395,
      "step": 190
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.181818181818182e-05,
      "loss": 0.9908,
      "step": 192
    },
    {
      "epoch": 0.5,
      "learning_rate": 4.173160173160173e-05,
      "loss": 1.4917,
      "step": 194
    },
    {
      "epoch": 0.51,
      "learning_rate": 4.164502164502165e-05,
      "loss": 1.135,
      "step": 196
    },
    {
      "epoch": 0.51,
      "learning_rate": 4.155844155844156e-05,
      "loss": 1.0295,
      "step": 198
    },
    {
      "epoch": 0.52,
      "learning_rate": 4.1471861471861474e-05,
      "loss": 0.9762,
      "step": 200
    },
    {
      "epoch": 0.52,
      "eval_cer": 0.10378297660527626,
      "eval_loss": 1.1381295919418335,
      "eval_runtime": 113.2392,
      "eval_samples_per_second": 6.8,
      "eval_steps_per_second": 0.857,
      "step": 200
    },
    {
      "epoch": 0.52,
      "learning_rate": 4.1385281385281386e-05,
      "loss": 1.3336,
      "step": 202
    },
    {
      "epoch": 0.53,
      "learning_rate": 4.1298701298701304e-05,
      "loss": 1.3435,
      "step": 204
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.1212121212121216e-05,
      "loss": 1.2859,
      "step": 206
    },
    {
      "epoch": 0.54,
      "learning_rate": 4.112554112554113e-05,
      "loss": 1.3013,
      "step": 208
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.103896103896104e-05,
      "loss": 1.1126,
      "step": 210
    },
    {
      "epoch": 0.55,
      "learning_rate": 4.095238095238095e-05,
      "loss": 1.2146,
      "step": 212
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.086580086580087e-05,
      "loss": 1.2356,
      "step": 214
    },
    {
      "epoch": 0.56,
      "learning_rate": 4.077922077922078e-05,
      "loss": 1.2743,
      "step": 216
    },
    {
      "epoch": 0.57,
      "learning_rate": 4.0692640692640695e-05,
      "loss": 0.8717,
      "step": 218
    },
    {
      "epoch": 0.57,
      "learning_rate": 4.0606060606060606e-05,
      "loss": 0.9728,
      "step": 220
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.0519480519480525e-05,
      "loss": 1.4029,
      "step": 222
    },
    {
      "epoch": 0.58,
      "learning_rate": 4.043290043290043e-05,
      "loss": 1.1204,
      "step": 224
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.034632034632035e-05,
      "loss": 0.7297,
      "step": 226
    },
    {
      "epoch": 0.59,
      "learning_rate": 4.025974025974026e-05,
      "loss": 1.1115,
      "step": 228
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.017316017316017e-05,
      "loss": 1.4828,
      "step": 230
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.008658008658009e-05,
      "loss": 1.0712,
      "step": 232
    },
    {
      "epoch": 0.61,
      "learning_rate": 4e-05,
      "loss": 1.0646,
      "step": 234
    },
    {
      "epoch": 0.61,
      "learning_rate": 3.9913419913419915e-05,
      "loss": 1.0387,
      "step": 236
    },
    {
      "epoch": 0.62,
      "learning_rate": 3.982683982683983e-05,
      "loss": 1.0354,
      "step": 238
    },
    {
      "epoch": 0.62,
      "learning_rate": 3.9740259740259746e-05,
      "loss": 1.5208,
      "step": 240
    },
    {
      "epoch": 0.63,
      "learning_rate": 3.965367965367965e-05,
      "loss": 1.819,
      "step": 242
    },
    {
      "epoch": 0.63,
      "learning_rate": 3.956709956709957e-05,
      "loss": 2.0178,
      "step": 244
    },
    {
      "epoch": 0.64,
      "learning_rate": 3.948051948051948e-05,
      "loss": 1.2084,
      "step": 246
    },
    {
      "epoch": 0.64,
      "learning_rate": 3.939393939393939e-05,
      "loss": 1.1733,
      "step": 248
    },
    {
      "epoch": 0.65,
      "learning_rate": 3.930735930735931e-05,
      "loss": 1.2952,
      "step": 250
    },
    {
      "epoch": 0.65,
      "learning_rate": 3.9220779220779224e-05,
      "loss": 1.1626,
      "step": 252
    },
    {
      "epoch": 0.66,
      "learning_rate": 3.9134199134199136e-05,
      "loss": 0.9013,
      "step": 254
    },
    {
      "epoch": 0.66,
      "learning_rate": 3.904761904761905e-05,
      "loss": 1.1413,
      "step": 256
    },
    {
      "epoch": 0.67,
      "learning_rate": 3.8961038961038966e-05,
      "loss": 0.9685,
      "step": 258
    },
    {
      "epoch": 0.68,
      "learning_rate": 3.887445887445887e-05,
      "loss": 1.0323,
      "step": 260
    },
    {
      "epoch": 0.68,
      "learning_rate": 3.878787878787879e-05,
      "loss": 0.9911,
      "step": 262
    },
    {
      "epoch": 0.69,
      "learning_rate": 3.87012987012987e-05,
      "loss": 1.0132,
      "step": 264
    },
    {
      "epoch": 0.69,
      "learning_rate": 3.8614718614718614e-05,
      "loss": 0.9464,
      "step": 266
    },
    {
      "epoch": 0.7,
      "learning_rate": 3.852813852813853e-05,
      "loss": 1.2468,
      "step": 268
    },
    {
      "epoch": 0.7,
      "learning_rate": 3.8441558441558445e-05,
      "loss": 1.0457,
      "step": 270
    },
    {
      "epoch": 0.71,
      "learning_rate": 3.8354978354978357e-05,
      "loss": 1.5436,
      "step": 272
    },
    {
      "epoch": 0.71,
      "learning_rate": 3.826839826839827e-05,
      "loss": 1.2718,
      "step": 274
    },
    {
      "epoch": 0.72,
      "learning_rate": 3.818181818181819e-05,
      "loss": 1.2708,
      "step": 276
    },
    {
      "epoch": 0.72,
      "learning_rate": 3.809523809523809e-05,
      "loss": 1.0426,
      "step": 278
    },
    {
      "epoch": 0.73,
      "learning_rate": 3.800865800865801e-05,
      "loss": 0.9985,
      "step": 280
    },
    {
      "epoch": 0.73,
      "learning_rate": 3.792207792207792e-05,
      "loss": 0.9771,
      "step": 282
    },
    {
      "epoch": 0.74,
      "learning_rate": 3.7835497835497835e-05,
      "loss": 1.4406,
      "step": 284
    },
    {
      "epoch": 0.74,
      "learning_rate": 3.774891774891775e-05,
      "loss": 1.2259,
      "step": 286
    },
    {
      "epoch": 0.75,
      "learning_rate": 3.7662337662337665e-05,
      "loss": 1.0037,
      "step": 288
    },
    {
      "epoch": 0.75,
      "learning_rate": 3.757575757575758e-05,
      "loss": 0.9363,
      "step": 290
    },
    {
      "epoch": 0.76,
      "learning_rate": 3.748917748917749e-05,
      "loss": 1.2054,
      "step": 292
    },
    {
      "epoch": 0.76,
      "learning_rate": 3.740259740259741e-05,
      "loss": 1.2464,
      "step": 294
    },
    {
      "epoch": 0.77,
      "learning_rate": 3.731601731601731e-05,
      "loss": 1.9182,
      "step": 296
    },
    {
      "epoch": 0.77,
      "learning_rate": 3.722943722943723e-05,
      "loss": 1.3296,
      "step": 298
    },
    {
      "epoch": 0.78,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 1.5301,
      "step": 300
    },
    {
      "epoch": 0.78,
      "learning_rate": 3.7056277056277055e-05,
      "loss": 1.201,
      "step": 302
    },
    {
      "epoch": 0.79,
      "learning_rate": 3.6969696969696974e-05,
      "loss": 1.1282,
      "step": 304
    },
    {
      "epoch": 0.79,
      "learning_rate": 3.6883116883116886e-05,
      "loss": 0.8412,
      "step": 306
    },
    {
      "epoch": 0.8,
      "learning_rate": 3.67965367965368e-05,
      "loss": 0.9742,
      "step": 308
    },
    {
      "epoch": 0.81,
      "learning_rate": 3.670995670995671e-05,
      "loss": 1.0749,
      "step": 310
    },
    {
      "epoch": 0.81,
      "learning_rate": 3.662337662337663e-05,
      "loss": 0.9675,
      "step": 312
    },
    {
      "epoch": 0.82,
      "learning_rate": 3.6536796536796534e-05,
      "loss": 1.132,
      "step": 314
    },
    {
      "epoch": 0.82,
      "learning_rate": 3.645021645021645e-05,
      "loss": 1.2446,
      "step": 316
    },
    {
      "epoch": 0.83,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.6065,
      "step": 318
    },
    {
      "epoch": 0.83,
      "learning_rate": 3.6277056277056276e-05,
      "loss": 0.9474,
      "step": 320
    },
    {
      "epoch": 0.84,
      "learning_rate": 3.619047619047619e-05,
      "loss": 1.0265,
      "step": 322
    },
    {
      "epoch": 0.84,
      "learning_rate": 3.610389610389611e-05,
      "loss": 0.885,
      "step": 324
    },
    {
      "epoch": 0.85,
      "learning_rate": 3.601731601731602e-05,
      "loss": 1.0282,
      "step": 326
    },
    {
      "epoch": 0.85,
      "learning_rate": 3.593073593073593e-05,
      "loss": 0.9579,
      "step": 328
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.584415584415585e-05,
      "loss": 0.6306,
      "step": 330
    },
    {
      "epoch": 0.86,
      "learning_rate": 3.575757575757576e-05,
      "loss": 1.179,
      "step": 332
    },
    {
      "epoch": 0.87,
      "learning_rate": 3.567099567099567e-05,
      "loss": 0.9623,
      "step": 334
    },
    {
      "epoch": 0.87,
      "learning_rate": 3.5584415584415585e-05,
      "loss": 0.9173,
      "step": 336
    },
    {
      "epoch": 0.88,
      "learning_rate": 3.5497835497835503e-05,
      "loss": 1.1063,
      "step": 338
    },
    {
      "epoch": 0.88,
      "learning_rate": 3.541125541125541e-05,
      "loss": 0.9223,
      "step": 340
    },
    {
      "epoch": 0.89,
      "learning_rate": 3.532467532467533e-05,
      "loss": 1.0477,
      "step": 342
    },
    {
      "epoch": 0.89,
      "learning_rate": 3.523809523809524e-05,
      "loss": 0.8395,
      "step": 344
    },
    {
      "epoch": 0.9,
      "learning_rate": 3.515151515151515e-05,
      "loss": 0.9741,
      "step": 346
    },
    {
      "epoch": 0.9,
      "learning_rate": 3.506493506493507e-05,
      "loss": 1.0935,
      "step": 348
    },
    {
      "epoch": 0.91,
      "learning_rate": 3.497835497835498e-05,
      "loss": 0.8882,
      "step": 350
    },
    {
      "epoch": 0.91,
      "learning_rate": 3.4891774891774894e-05,
      "loss": 1.0314,
      "step": 352
    },
    {
      "epoch": 0.92,
      "learning_rate": 3.4805194805194805e-05,
      "loss": 1.046,
      "step": 354
    },
    {
      "epoch": 0.92,
      "learning_rate": 3.4718614718614724e-05,
      "loss": 0.892,
      "step": 356
    },
    {
      "epoch": 0.93,
      "learning_rate": 3.463203463203463e-05,
      "loss": 0.9596,
      "step": 358
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.454545454545455e-05,
      "loss": 0.9085,
      "step": 360
    },
    {
      "epoch": 0.94,
      "learning_rate": 3.445887445887446e-05,
      "loss": 0.766,
      "step": 362
    },
    {
      "epoch": 0.95,
      "learning_rate": 3.437229437229437e-05,
      "loss": 1.0736,
      "step": 364
    },
    {
      "epoch": 0.95,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.8765,
      "step": 366
    },
    {
      "epoch": 0.96,
      "learning_rate": 3.41991341991342e-05,
      "loss": 0.9805,
      "step": 368
    },
    {
      "epoch": 0.96,
      "learning_rate": 3.4112554112554114e-05,
      "loss": 0.8931,
      "step": 370
    },
    {
      "epoch": 0.97,
      "learning_rate": 3.4025974025974026e-05,
      "loss": 1.174,
      "step": 372
    },
    {
      "epoch": 0.97,
      "learning_rate": 3.3939393939393945e-05,
      "loss": 0.8052,
      "step": 374
    },
    {
      "epoch": 0.98,
      "learning_rate": 3.385281385281385e-05,
      "loss": 1.0044,
      "step": 376
    },
    {
      "epoch": 0.98,
      "learning_rate": 3.376623376623377e-05,
      "loss": 0.7554,
      "step": 378
    },
    {
      "epoch": 0.99,
      "learning_rate": 3.367965367965368e-05,
      "loss": 0.856,
      "step": 380
    },
    {
      "epoch": 0.99,
      "learning_rate": 3.359307359307359e-05,
      "loss": 0.7508,
      "step": 382
    },
    {
      "epoch": 1.0,
      "learning_rate": 3.350649350649351e-05,
      "loss": 1.1834,
      "step": 384
    },
    {
      "epoch": 1.0,
      "learning_rate": 3.341991341991342e-05,
      "loss": 0.9874,
      "step": 386
    },
    {
      "epoch": 1.01,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.8998,
      "step": 388
    },
    {
      "epoch": 1.01,
      "learning_rate": 3.324675324675325e-05,
      "loss": 0.8377,
      "step": 390
    },
    {
      "epoch": 1.02,
      "learning_rate": 3.3160173160173166e-05,
      "loss": 0.8855,
      "step": 392
    },
    {
      "epoch": 1.02,
      "learning_rate": 3.307359307359307e-05,
      "loss": 0.8167,
      "step": 394
    },
    {
      "epoch": 1.03,
      "learning_rate": 3.298701298701299e-05,
      "loss": 0.8104,
      "step": 396
    },
    {
      "epoch": 1.03,
      "learning_rate": 3.29004329004329e-05,
      "loss": 0.53,
      "step": 398
    },
    {
      "epoch": 1.04,
      "learning_rate": 3.281385281385281e-05,
      "loss": 0.9316,
      "step": 400
    },
    {
      "epoch": 1.04,
      "eval_cer": 0.06520657043305127,
      "eval_loss": 0.9915670156478882,
      "eval_runtime": 104.2164,
      "eval_samples_per_second": 7.388,
      "eval_steps_per_second": 0.931,
      "step": 400
    },
    {
      "epoch": 1.04,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.7782,
      "step": 402
    },
    {
      "epoch": 1.05,
      "learning_rate": 3.2640692640692644e-05,
      "loss": 0.6714,
      "step": 404
    },
    {
      "epoch": 1.05,
      "learning_rate": 3.2554112554112556e-05,
      "loss": 0.9611,
      "step": 406
    },
    {
      "epoch": 1.06,
      "learning_rate": 3.246753246753247e-05,
      "loss": 0.969,
      "step": 408
    },
    {
      "epoch": 1.06,
      "learning_rate": 3.2380952380952386e-05,
      "loss": 0.9563,
      "step": 410
    },
    {
      "epoch": 1.07,
      "learning_rate": 3.229437229437229e-05,
      "loss": 1.2041,
      "step": 412
    },
    {
      "epoch": 1.08,
      "learning_rate": 3.220779220779221e-05,
      "loss": 0.6841,
      "step": 414
    },
    {
      "epoch": 1.08,
      "learning_rate": 3.212121212121212e-05,
      "loss": 0.6981,
      "step": 416
    },
    {
      "epoch": 1.09,
      "learning_rate": 3.2034632034632034e-05,
      "loss": 0.8472,
      "step": 418
    },
    {
      "epoch": 1.09,
      "learning_rate": 3.194805194805195e-05,
      "loss": 0.9702,
      "step": 420
    },
    {
      "epoch": 1.1,
      "learning_rate": 3.1861471861471864e-05,
      "loss": 0.8898,
      "step": 422
    },
    {
      "epoch": 1.1,
      "learning_rate": 3.1774891774891776e-05,
      "loss": 0.6363,
      "step": 424
    },
    {
      "epoch": 1.11,
      "learning_rate": 3.168831168831169e-05,
      "loss": 0.8736,
      "step": 426
    },
    {
      "epoch": 1.11,
      "learning_rate": 3.160173160173161e-05,
      "loss": 0.6899,
      "step": 428
    },
    {
      "epoch": 1.12,
      "learning_rate": 3.151515151515151e-05,
      "loss": 0.7512,
      "step": 430
    },
    {
      "epoch": 1.12,
      "learning_rate": 3.142857142857143e-05,
      "loss": 0.9385,
      "step": 432
    },
    {
      "epoch": 1.13,
      "learning_rate": 3.134199134199134e-05,
      "loss": 1.0996,
      "step": 434
    },
    {
      "epoch": 1.13,
      "learning_rate": 3.1255411255411254e-05,
      "loss": 0.7342,
      "step": 436
    },
    {
      "epoch": 1.14,
      "learning_rate": 3.1168831168831166e-05,
      "loss": 0.9348,
      "step": 438
    },
    {
      "epoch": 1.14,
      "learning_rate": 3.1082251082251085e-05,
      "loss": 1.1382,
      "step": 440
    },
    {
      "epoch": 1.15,
      "learning_rate": 3.0995670995671e-05,
      "loss": 1.0413,
      "step": 442
    },
    {
      "epoch": 1.15,
      "learning_rate": 3.090909090909091e-05,
      "loss": 0.7752,
      "step": 444
    },
    {
      "epoch": 1.16,
      "learning_rate": 3.082251082251083e-05,
      "loss": 1.0975,
      "step": 446
    },
    {
      "epoch": 1.16,
      "learning_rate": 3.073593073593073e-05,
      "loss": 1.0334,
      "step": 448
    },
    {
      "epoch": 1.17,
      "learning_rate": 3.064935064935065e-05,
      "loss": 1.0747,
      "step": 450
    },
    {
      "epoch": 1.17,
      "learning_rate": 3.056277056277056e-05,
      "loss": 0.8247,
      "step": 452
    },
    {
      "epoch": 1.18,
      "learning_rate": 3.0476190476190482e-05,
      "loss": 0.9264,
      "step": 454
    },
    {
      "epoch": 1.18,
      "learning_rate": 3.038961038961039e-05,
      "loss": 0.9343,
      "step": 456
    },
    {
      "epoch": 1.19,
      "learning_rate": 3.0303030303030306e-05,
      "loss": 0.6567,
      "step": 458
    },
    {
      "epoch": 1.19,
      "learning_rate": 3.021645021645022e-05,
      "loss": 0.6734,
      "step": 460
    },
    {
      "epoch": 1.2,
      "learning_rate": 3.012987012987013e-05,
      "loss": 1.0702,
      "step": 462
    },
    {
      "epoch": 1.21,
      "learning_rate": 3.0043290043290045e-05,
      "loss": 0.913,
      "step": 464
    },
    {
      "epoch": 1.21,
      "learning_rate": 2.995670995670996e-05,
      "loss": 0.6616,
      "step": 466
    },
    {
      "epoch": 1.22,
      "learning_rate": 2.9870129870129872e-05,
      "loss": 0.698,
      "step": 468
    },
    {
      "epoch": 1.22,
      "learning_rate": 2.9783549783549787e-05,
      "loss": 0.7659,
      "step": 470
    },
    {
      "epoch": 1.23,
      "learning_rate": 2.96969696969697e-05,
      "loss": 0.6255,
      "step": 472
    },
    {
      "epoch": 1.23,
      "learning_rate": 2.961038961038961e-05,
      "loss": 0.6638,
      "step": 474
    },
    {
      "epoch": 1.24,
      "learning_rate": 2.9523809523809526e-05,
      "loss": 0.9604,
      "step": 476
    },
    {
      "epoch": 1.24,
      "learning_rate": 2.943722943722944e-05,
      "loss": 0.7154,
      "step": 478
    },
    {
      "epoch": 1.25,
      "learning_rate": 2.935064935064935e-05,
      "loss": 0.9261,
      "step": 480
    },
    {
      "epoch": 1.25,
      "learning_rate": 2.9264069264069265e-05,
      "loss": 0.8481,
      "step": 482
    },
    {
      "epoch": 1.26,
      "learning_rate": 2.917748917748918e-05,
      "loss": 0.6502,
      "step": 484
    },
    {
      "epoch": 1.26,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.7723,
      "step": 486
    },
    {
      "epoch": 1.27,
      "learning_rate": 2.9004329004329005e-05,
      "loss": 0.6062,
      "step": 488
    },
    {
      "epoch": 1.27,
      "learning_rate": 2.891774891774892e-05,
      "loss": 0.7603,
      "step": 490
    },
    {
      "epoch": 1.28,
      "learning_rate": 2.8831168831168832e-05,
      "loss": 0.5932,
      "step": 492
    },
    {
      "epoch": 1.28,
      "learning_rate": 2.8744588744588747e-05,
      "loss": 0.6711,
      "step": 494
    },
    {
      "epoch": 1.29,
      "learning_rate": 2.8658008658008662e-05,
      "loss": 0.7051,
      "step": 496
    },
    {
      "epoch": 1.29,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.8063,
      "step": 498
    },
    {
      "epoch": 1.3,
      "learning_rate": 2.8484848484848486e-05,
      "loss": 0.7574,
      "step": 500
    },
    {
      "epoch": 1.3,
      "learning_rate": 2.83982683982684e-05,
      "loss": 0.9589,
      "step": 502
    },
    {
      "epoch": 1.31,
      "learning_rate": 2.831168831168831e-05,
      "loss": 0.9593,
      "step": 504
    },
    {
      "epoch": 1.31,
      "learning_rate": 2.8225108225108225e-05,
      "loss": 0.8192,
      "step": 506
    },
    {
      "epoch": 1.32,
      "learning_rate": 2.813852813852814e-05,
      "loss": 0.9554,
      "step": 508
    },
    {
      "epoch": 1.32,
      "learning_rate": 2.8051948051948052e-05,
      "loss": 0.764,
      "step": 510
    },
    {
      "epoch": 1.33,
      "learning_rate": 2.7965367965367968e-05,
      "loss": 0.5929,
      "step": 512
    },
    {
      "epoch": 1.34,
      "learning_rate": 2.7878787878787883e-05,
      "loss": 0.6567,
      "step": 514
    },
    {
      "epoch": 1.34,
      "learning_rate": 2.779220779220779e-05,
      "loss": 0.9703,
      "step": 516
    },
    {
      "epoch": 1.35,
      "learning_rate": 2.7705627705627707e-05,
      "loss": 0.748,
      "step": 518
    },
    {
      "epoch": 1.35,
      "learning_rate": 2.7619047619047622e-05,
      "loss": 0.7101,
      "step": 520
    },
    {
      "epoch": 1.36,
      "learning_rate": 2.753246753246753e-05,
      "loss": 0.8071,
      "step": 522
    },
    {
      "epoch": 1.36,
      "learning_rate": 2.7445887445887446e-05,
      "loss": 0.8794,
      "step": 524
    },
    {
      "epoch": 1.37,
      "learning_rate": 2.735930735930736e-05,
      "loss": 0.6266,
      "step": 526
    },
    {
      "epoch": 1.37,
      "learning_rate": 2.7272727272727273e-05,
      "loss": 0.5868,
      "step": 528
    },
    {
      "epoch": 1.38,
      "learning_rate": 2.718614718614719e-05,
      "loss": 0.6399,
      "step": 530
    },
    {
      "epoch": 1.38,
      "learning_rate": 2.7099567099567104e-05,
      "loss": 0.5418,
      "step": 532
    },
    {
      "epoch": 1.39,
      "learning_rate": 2.7012987012987012e-05,
      "loss": 0.896,
      "step": 534
    },
    {
      "epoch": 1.39,
      "learning_rate": 2.6926406926406927e-05,
      "loss": 0.5544,
      "step": 536
    },
    {
      "epoch": 1.4,
      "learning_rate": 2.6839826839826843e-05,
      "loss": 0.8709,
      "step": 538
    },
    {
      "epoch": 1.4,
      "learning_rate": 2.675324675324675e-05,
      "loss": 0.6123,
      "step": 540
    },
    {
      "epoch": 1.41,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.6335,
      "step": 542
    },
    {
      "epoch": 1.41,
      "learning_rate": 2.6580086580086582e-05,
      "loss": 0.6172,
      "step": 544
    },
    {
      "epoch": 1.42,
      "learning_rate": 2.6493506493506494e-05,
      "loss": 0.7008,
      "step": 546
    },
    {
      "epoch": 1.42,
      "learning_rate": 2.640692640692641e-05,
      "loss": 0.7819,
      "step": 548
    },
    {
      "epoch": 1.43,
      "learning_rate": 2.6320346320346324e-05,
      "loss": 0.8031,
      "step": 550
    },
    {
      "epoch": 1.43,
      "learning_rate": 2.6233766233766233e-05,
      "loss": 0.5,
      "step": 552
    },
    {
      "epoch": 1.44,
      "learning_rate": 2.6147186147186148e-05,
      "loss": 0.7037,
      "step": 554
    },
    {
      "epoch": 1.44,
      "learning_rate": 2.6060606060606063e-05,
      "loss": 0.6655,
      "step": 556
    },
    {
      "epoch": 1.45,
      "learning_rate": 2.5974025974025972e-05,
      "loss": 0.825,
      "step": 558
    },
    {
      "epoch": 1.45,
      "learning_rate": 2.5887445887445887e-05,
      "loss": 0.5707,
      "step": 560
    },
    {
      "epoch": 1.46,
      "learning_rate": 2.5800865800865803e-05,
      "loss": 0.5179,
      "step": 562
    },
    {
      "epoch": 1.46,
      "learning_rate": 2.5714285714285714e-05,
      "loss": 0.8621,
      "step": 564
    },
    {
      "epoch": 1.47,
      "learning_rate": 2.562770562770563e-05,
      "loss": 0.7762,
      "step": 566
    },
    {
      "epoch": 1.48,
      "learning_rate": 2.5541125541125545e-05,
      "loss": 0.5091,
      "step": 568
    },
    {
      "epoch": 1.48,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.0017,
      "step": 570
    },
    {
      "epoch": 1.49,
      "learning_rate": 2.536796536796537e-05,
      "loss": 0.812,
      "step": 572
    },
    {
      "epoch": 1.49,
      "learning_rate": 2.5281385281385284e-05,
      "loss": 0.7859,
      "step": 574
    },
    {
      "epoch": 1.5,
      "learning_rate": 2.5194805194805193e-05,
      "loss": 0.5721,
      "step": 576
    },
    {
      "epoch": 1.5,
      "learning_rate": 2.5108225108225108e-05,
      "loss": 0.5312,
      "step": 578
    },
    {
      "epoch": 1.51,
      "learning_rate": 2.5021645021645023e-05,
      "loss": 0.6091,
      "step": 580
    },
    {
      "epoch": 1.51,
      "learning_rate": 2.4935064935064935e-05,
      "loss": 0.6329,
      "step": 582
    },
    {
      "epoch": 1.52,
      "learning_rate": 2.4848484848484847e-05,
      "loss": 0.7974,
      "step": 584
    },
    {
      "epoch": 1.52,
      "learning_rate": 2.4761904761904762e-05,
      "loss": 0.6717,
      "step": 586
    },
    {
      "epoch": 1.53,
      "learning_rate": 2.4675324675324678e-05,
      "loss": 0.6023,
      "step": 588
    },
    {
      "epoch": 1.53,
      "learning_rate": 2.458874458874459e-05,
      "loss": 0.5696,
      "step": 590
    },
    {
      "epoch": 1.54,
      "learning_rate": 2.4502164502164505e-05,
      "loss": 0.4671,
      "step": 592
    },
    {
      "epoch": 1.54,
      "learning_rate": 2.4415584415584417e-05,
      "loss": 0.7727,
      "step": 594
    },
    {
      "epoch": 1.55,
      "learning_rate": 2.432900432900433e-05,
      "loss": 0.6256,
      "step": 596
    },
    {
      "epoch": 1.55,
      "learning_rate": 2.4242424242424244e-05,
      "loss": 0.5972,
      "step": 598
    },
    {
      "epoch": 1.56,
      "learning_rate": 2.4155844155844156e-05,
      "loss": 0.6255,
      "step": 600
    },
    {
      "epoch": 1.56,
      "eval_cer": 0.027874564459930314,
      "eval_loss": 0.7415023446083069,
      "eval_runtime": 104.3892,
      "eval_samples_per_second": 7.376,
      "eval_steps_per_second": 0.929,
      "step": 600
    },
    {
      "epoch": 1.56,
      "learning_rate": 2.4069264069264068e-05,
      "loss": 0.5953,
      "step": 602
    },
    {
      "epoch": 1.57,
      "learning_rate": 2.3982683982683983e-05,
      "loss": 0.6269,
      "step": 604
    },
    {
      "epoch": 1.57,
      "learning_rate": 2.3896103896103898e-05,
      "loss": 0.5328,
      "step": 606
    },
    {
      "epoch": 1.58,
      "learning_rate": 2.380952380952381e-05,
      "loss": 0.6616,
      "step": 608
    },
    {
      "epoch": 1.58,
      "learning_rate": 2.3722943722943725e-05,
      "loss": 0.6487,
      "step": 610
    },
    {
      "epoch": 1.59,
      "learning_rate": 2.3636363636363637e-05,
      "loss": 0.6558,
      "step": 612
    },
    {
      "epoch": 1.59,
      "learning_rate": 2.3549783549783553e-05,
      "loss": 0.6941,
      "step": 614
    },
    {
      "epoch": 1.6,
      "learning_rate": 2.3463203463203465e-05,
      "loss": 0.9175,
      "step": 616
    },
    {
      "epoch": 1.61,
      "learning_rate": 2.3376623376623376e-05,
      "loss": 0.7358,
      "step": 618
    },
    {
      "epoch": 1.61,
      "learning_rate": 2.3290043290043292e-05,
      "loss": 0.664,
      "step": 620
    },
    {
      "epoch": 1.62,
      "learning_rate": 2.3203463203463204e-05,
      "loss": 0.6595,
      "step": 622
    },
    {
      "epoch": 1.62,
      "learning_rate": 2.311688311688312e-05,
      "loss": 0.6539,
      "step": 624
    },
    {
      "epoch": 1.63,
      "learning_rate": 2.3030303030303034e-05,
      "loss": 0.538,
      "step": 626
    },
    {
      "epoch": 1.63,
      "learning_rate": 2.2943722943722946e-05,
      "loss": 0.5283,
      "step": 628
    },
    {
      "epoch": 1.64,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 0.9194,
      "step": 630
    },
    {
      "epoch": 1.64,
      "learning_rate": 2.2770562770562773e-05,
      "loss": 0.5831,
      "step": 632
    },
    {
      "epoch": 1.65,
      "learning_rate": 2.2683982683982685e-05,
      "loss": 0.6844,
      "step": 634
    },
    {
      "epoch": 1.65,
      "learning_rate": 2.2597402597402597e-05,
      "loss": 0.6181,
      "step": 636
    },
    {
      "epoch": 1.66,
      "learning_rate": 2.2510822510822512e-05,
      "loss": 0.4999,
      "step": 638
    },
    {
      "epoch": 1.66,
      "learning_rate": 2.2424242424242424e-05,
      "loss": 0.6891,
      "step": 640
    },
    {
      "epoch": 1.67,
      "learning_rate": 2.2337662337662336e-05,
      "loss": 0.5877,
      "step": 642
    },
    {
      "epoch": 1.67,
      "learning_rate": 2.225108225108225e-05,
      "loss": 0.5969,
      "step": 644
    },
    {
      "epoch": 1.68,
      "learning_rate": 2.2164502164502167e-05,
      "loss": 0.6889,
      "step": 646
    },
    {
      "epoch": 1.68,
      "learning_rate": 2.207792207792208e-05,
      "loss": 0.997,
      "step": 648
    },
    {
      "epoch": 1.69,
      "learning_rate": 2.1991341991341994e-05,
      "loss": 0.7157,
      "step": 650
    },
    {
      "epoch": 1.69,
      "learning_rate": 2.1904761904761906e-05,
      "loss": 1.0619,
      "step": 652
    },
    {
      "epoch": 1.7,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.6376,
      "step": 654
    },
    {
      "epoch": 1.7,
      "learning_rate": 2.1731601731601733e-05,
      "loss": 0.6874,
      "step": 656
    },
    {
      "epoch": 1.71,
      "learning_rate": 2.1645021645021645e-05,
      "loss": 0.9914,
      "step": 658
    },
    {
      "epoch": 1.71,
      "learning_rate": 2.1558441558441557e-05,
      "loss": 0.6427,
      "step": 660
    },
    {
      "epoch": 1.72,
      "learning_rate": 2.1471861471861472e-05,
      "loss": 0.8356,
      "step": 662
    },
    {
      "epoch": 1.72,
      "learning_rate": 2.1385281385281387e-05,
      "loss": 0.8834,
      "step": 664
    },
    {
      "epoch": 1.73,
      "learning_rate": 2.12987012987013e-05,
      "loss": 0.5189,
      "step": 666
    },
    {
      "epoch": 1.74,
      "learning_rate": 2.1212121212121215e-05,
      "loss": 0.705,
      "step": 668
    },
    {
      "epoch": 1.74,
      "learning_rate": 2.1125541125541127e-05,
      "loss": 0.6103,
      "step": 670
    },
    {
      "epoch": 1.75,
      "learning_rate": 2.103896103896104e-05,
      "loss": 0.7187,
      "step": 672
    },
    {
      "epoch": 1.75,
      "learning_rate": 2.0952380952380954e-05,
      "loss": 0.7266,
      "step": 674
    },
    {
      "epoch": 1.76,
      "learning_rate": 2.0865800865800866e-05,
      "loss": 0.8451,
      "step": 676
    },
    {
      "epoch": 1.76,
      "learning_rate": 2.077922077922078e-05,
      "loss": 0.5684,
      "step": 678
    },
    {
      "epoch": 1.77,
      "learning_rate": 2.0692640692640693e-05,
      "loss": 0.6615,
      "step": 680
    },
    {
      "epoch": 1.77,
      "learning_rate": 2.0606060606060608e-05,
      "loss": 0.6479,
      "step": 682
    },
    {
      "epoch": 1.78,
      "learning_rate": 2.051948051948052e-05,
      "loss": 0.6049,
      "step": 684
    },
    {
      "epoch": 1.78,
      "learning_rate": 2.0432900432900435e-05,
      "loss": 0.6648,
      "step": 686
    },
    {
      "epoch": 1.79,
      "learning_rate": 2.0346320346320347e-05,
      "loss": 0.5539,
      "step": 688
    },
    {
      "epoch": 1.79,
      "learning_rate": 2.0259740259740263e-05,
      "loss": 0.5759,
      "step": 690
    },
    {
      "epoch": 1.8,
      "learning_rate": 2.0173160173160174e-05,
      "loss": 0.5932,
      "step": 692
    },
    {
      "epoch": 1.8,
      "learning_rate": 2.0086580086580086e-05,
      "loss": 0.5492,
      "step": 694
    },
    {
      "epoch": 1.81,
      "learning_rate": 2e-05,
      "loss": 0.8451,
      "step": 696
    },
    {
      "epoch": 1.81,
      "learning_rate": 1.9913419913419914e-05,
      "loss": 0.7496,
      "step": 698
    },
    {
      "epoch": 1.82,
      "learning_rate": 1.9826839826839825e-05,
      "loss": 0.5843,
      "step": 700
    },
    {
      "epoch": 1.82,
      "learning_rate": 1.974025974025974e-05,
      "loss": 0.5875,
      "step": 702
    },
    {
      "epoch": 1.83,
      "learning_rate": 1.9653679653679656e-05,
      "loss": 0.6377,
      "step": 704
    },
    {
      "epoch": 1.83,
      "learning_rate": 1.9567099567099568e-05,
      "loss": 0.4549,
      "step": 706
    },
    {
      "epoch": 1.84,
      "learning_rate": 1.9480519480519483e-05,
      "loss": 0.6719,
      "step": 708
    },
    {
      "epoch": 1.84,
      "learning_rate": 1.9393939393939395e-05,
      "loss": 0.5086,
      "step": 710
    },
    {
      "epoch": 1.85,
      "learning_rate": 1.9307359307359307e-05,
      "loss": 0.5428,
      "step": 712
    },
    {
      "epoch": 1.85,
      "learning_rate": 1.9220779220779222e-05,
      "loss": 0.4508,
      "step": 714
    },
    {
      "epoch": 1.86,
      "learning_rate": 1.9134199134199134e-05,
      "loss": 0.4977,
      "step": 716
    },
    {
      "epoch": 1.86,
      "learning_rate": 1.9047619047619046e-05,
      "loss": 0.5892,
      "step": 718
    },
    {
      "epoch": 1.87,
      "learning_rate": 1.896103896103896e-05,
      "loss": 0.4982,
      "step": 720
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.8874458874458877e-05,
      "loss": 0.7295,
      "step": 722
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.878787878787879e-05,
      "loss": 0.4665,
      "step": 724
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.8701298701298704e-05,
      "loss": 0.7422,
      "step": 726
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.8614718614718616e-05,
      "loss": 0.7614,
      "step": 728
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.8528138528138528e-05,
      "loss": 0.558,
      "step": 730
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.8441558441558443e-05,
      "loss": 0.7513,
      "step": 732
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.8354978354978355e-05,
      "loss": 0.5474,
      "step": 734
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.8268398268398267e-05,
      "loss": 0.5002,
      "step": 736
    },
    {
      "epoch": 1.92,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.5366,
      "step": 738
    },
    {
      "epoch": 1.92,
      "learning_rate": 1.8095238095238094e-05,
      "loss": 0.7197,
      "step": 740
    },
    {
      "epoch": 1.93,
      "learning_rate": 1.800865800865801e-05,
      "loss": 0.6129,
      "step": 742
    },
    {
      "epoch": 1.93,
      "learning_rate": 1.7922077922077925e-05,
      "loss": 0.5133,
      "step": 744
    },
    {
      "epoch": 1.94,
      "learning_rate": 1.7835497835497836e-05,
      "loss": 0.4693,
      "step": 746
    },
    {
      "epoch": 1.94,
      "learning_rate": 1.7748917748917752e-05,
      "loss": 0.7365,
      "step": 748
    },
    {
      "epoch": 1.95,
      "learning_rate": 1.7662337662337664e-05,
      "loss": 0.6526,
      "step": 750
    },
    {
      "epoch": 1.95,
      "learning_rate": 1.7575757575757576e-05,
      "loss": 0.7162,
      "step": 752
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.748917748917749e-05,
      "loss": 0.6688,
      "step": 754
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.7402597402597403e-05,
      "loss": 0.5429,
      "step": 756
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.7316017316017315e-05,
      "loss": 0.679,
      "step": 758
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.722943722943723e-05,
      "loss": 0.6521,
      "step": 760
    },
    {
      "epoch": 1.98,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.7759,
      "step": 762
    },
    {
      "epoch": 1.98,
      "learning_rate": 1.7056277056277057e-05,
      "loss": 0.7004,
      "step": 764
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.6969696969696972e-05,
      "loss": 0.5383,
      "step": 766
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.6883116883116884e-05,
      "loss": 0.4982,
      "step": 768
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.6796536796536796e-05,
      "loss": 0.7447,
      "step": 770
    },
    {
      "epoch": 2.01,
      "learning_rate": 1.670995670995671e-05,
      "loss": 0.5216,
      "step": 772
    },
    {
      "epoch": 2.01,
      "learning_rate": 1.6623376623376623e-05,
      "loss": 0.5968,
      "step": 774
    },
    {
      "epoch": 2.02,
      "learning_rate": 1.6536796536796535e-05,
      "loss": 0.4609,
      "step": 776
    },
    {
      "epoch": 2.02,
      "learning_rate": 1.645021645021645e-05,
      "loss": 0.5089,
      "step": 778
    },
    {
      "epoch": 2.03,
      "learning_rate": 1.6363636363636366e-05,
      "loss": 0.5391,
      "step": 780
    },
    {
      "epoch": 2.03,
      "learning_rate": 1.6277056277056278e-05,
      "loss": 0.4829,
      "step": 782
    },
    {
      "epoch": 2.04,
      "learning_rate": 1.6190476190476193e-05,
      "loss": 0.4978,
      "step": 784
    },
    {
      "epoch": 2.04,
      "learning_rate": 1.6103896103896105e-05,
      "loss": 0.6253,
      "step": 786
    },
    {
      "epoch": 2.05,
      "learning_rate": 1.6017316017316017e-05,
      "loss": 0.4552,
      "step": 788
    },
    {
      "epoch": 2.05,
      "learning_rate": 1.5930735930735932e-05,
      "loss": 0.4587,
      "step": 790
    },
    {
      "epoch": 2.06,
      "learning_rate": 1.5844155844155844e-05,
      "loss": 0.5144,
      "step": 792
    },
    {
      "epoch": 2.06,
      "learning_rate": 1.5757575757575756e-05,
      "loss": 0.4554,
      "step": 794
    },
    {
      "epoch": 2.07,
      "learning_rate": 1.567099567099567e-05,
      "loss": 0.5639,
      "step": 796
    },
    {
      "epoch": 2.07,
      "learning_rate": 1.5584415584415583e-05,
      "loss": 0.4287,
      "step": 798
    },
    {
      "epoch": 2.08,
      "learning_rate": 1.54978354978355e-05,
      "loss": 0.5887,
      "step": 800
    },
    {
      "epoch": 2.08,
      "eval_cer": 0.02538576406172225,
      "eval_loss": 0.6465562582015991,
      "eval_runtime": 105.2661,
      "eval_samples_per_second": 7.315,
      "eval_steps_per_second": 0.921,
      "step": 800
    },
    {
      "epoch": 2.08,
      "learning_rate": 1.5411255411255414e-05,
      "loss": 0.4943,
      "step": 802
    },
    {
      "epoch": 2.09,
      "learning_rate": 1.5324675324675326e-05,
      "loss": 0.4985,
      "step": 804
    },
    {
      "epoch": 2.09,
      "learning_rate": 1.5238095238095241e-05,
      "loss": 0.4319,
      "step": 806
    },
    {
      "epoch": 2.1,
      "learning_rate": 1.5151515151515153e-05,
      "loss": 0.4038,
      "step": 808
    },
    {
      "epoch": 2.1,
      "learning_rate": 1.5064935064935065e-05,
      "loss": 0.4541,
      "step": 810
    },
    {
      "epoch": 2.11,
      "learning_rate": 1.497835497835498e-05,
      "loss": 0.443,
      "step": 812
    },
    {
      "epoch": 2.11,
      "learning_rate": 1.4891774891774894e-05,
      "loss": 0.5341,
      "step": 814
    },
    {
      "epoch": 2.12,
      "learning_rate": 1.4805194805194806e-05,
      "loss": 0.4695,
      "step": 816
    },
    {
      "epoch": 2.12,
      "learning_rate": 1.471861471861472e-05,
      "loss": 0.3882,
      "step": 818
    },
    {
      "epoch": 2.13,
      "learning_rate": 1.4632034632034633e-05,
      "loss": 0.6599,
      "step": 820
    },
    {
      "epoch": 2.14,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.4359,
      "step": 822
    },
    {
      "epoch": 2.14,
      "learning_rate": 1.445887445887446e-05,
      "loss": 0.4768,
      "step": 824
    },
    {
      "epoch": 2.15,
      "learning_rate": 1.4372294372294374e-05,
      "loss": 0.4169,
      "step": 826
    },
    {
      "epoch": 2.15,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.4554,
      "step": 828
    },
    {
      "epoch": 2.16,
      "learning_rate": 1.41991341991342e-05,
      "loss": 0.4629,
      "step": 830
    },
    {
      "epoch": 2.16,
      "learning_rate": 1.4112554112554113e-05,
      "loss": 0.4705,
      "step": 832
    },
    {
      "epoch": 2.17,
      "learning_rate": 1.4025974025974026e-05,
      "loss": 0.5374,
      "step": 834
    },
    {
      "epoch": 2.17,
      "learning_rate": 1.3939393939393942e-05,
      "loss": 0.4109,
      "step": 836
    },
    {
      "epoch": 2.18,
      "learning_rate": 1.3852813852813853e-05,
      "loss": 0.5843,
      "step": 838
    },
    {
      "epoch": 2.18,
      "learning_rate": 1.3766233766233765e-05,
      "loss": 0.4968,
      "step": 840
    },
    {
      "epoch": 2.19,
      "learning_rate": 1.367965367965368e-05,
      "loss": 0.4593,
      "step": 842
    },
    {
      "epoch": 2.19,
      "learning_rate": 1.3593073593073594e-05,
      "loss": 0.5274,
      "step": 844
    },
    {
      "epoch": 2.2,
      "learning_rate": 1.3506493506493506e-05,
      "loss": 0.4908,
      "step": 846
    },
    {
      "epoch": 2.2,
      "learning_rate": 1.3419913419913421e-05,
      "loss": 0.519,
      "step": 848
    },
    {
      "epoch": 2.21,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.4238,
      "step": 850
    },
    {
      "epoch": 2.21,
      "learning_rate": 1.3246753246753247e-05,
      "loss": 0.5689,
      "step": 852
    },
    {
      "epoch": 2.22,
      "learning_rate": 1.3160173160173162e-05,
      "loss": 0.4065,
      "step": 854
    },
    {
      "epoch": 2.22,
      "learning_rate": 1.3073593073593074e-05,
      "loss": 0.6105,
      "step": 856
    },
    {
      "epoch": 2.23,
      "learning_rate": 1.2987012987012986e-05,
      "loss": 0.4325,
      "step": 858
    },
    {
      "epoch": 2.23,
      "learning_rate": 1.2900432900432901e-05,
      "loss": 0.4825,
      "step": 860
    },
    {
      "epoch": 2.24,
      "learning_rate": 1.2813852813852815e-05,
      "loss": 0.4725,
      "step": 862
    },
    {
      "epoch": 2.24,
      "learning_rate": 1.2727272727272727e-05,
      "loss": 0.4403,
      "step": 864
    },
    {
      "epoch": 2.25,
      "learning_rate": 1.2640692640692642e-05,
      "loss": 0.6891,
      "step": 866
    },
    {
      "epoch": 2.25,
      "learning_rate": 1.2554112554112554e-05,
      "loss": 0.4427,
      "step": 868
    },
    {
      "epoch": 2.26,
      "learning_rate": 1.2467532467532468e-05,
      "loss": 0.422,
      "step": 870
    },
    {
      "epoch": 2.26,
      "learning_rate": 1.2380952380952381e-05,
      "loss": 0.4411,
      "step": 872
    },
    {
      "epoch": 2.27,
      "learning_rate": 1.2294372294372295e-05,
      "loss": 0.6825,
      "step": 874
    },
    {
      "epoch": 2.28,
      "learning_rate": 1.2207792207792208e-05,
      "loss": 0.4362,
      "step": 876
    },
    {
      "epoch": 2.28,
      "learning_rate": 1.2121212121212122e-05,
      "loss": 0.4253,
      "step": 878
    },
    {
      "epoch": 2.29,
      "learning_rate": 1.2034632034632034e-05,
      "loss": 0.4732,
      "step": 880
    },
    {
      "epoch": 2.29,
      "learning_rate": 1.1948051948051949e-05,
      "loss": 0.4588,
      "step": 882
    },
    {
      "epoch": 2.3,
      "learning_rate": 1.1861471861471863e-05,
      "loss": 0.5428,
      "step": 884
    },
    {
      "epoch": 2.3,
      "learning_rate": 1.1774891774891776e-05,
      "loss": 0.6734,
      "step": 886
    },
    {
      "epoch": 2.31,
      "learning_rate": 1.1688311688311688e-05,
      "loss": 0.6679,
      "step": 888
    },
    {
      "epoch": 2.31,
      "learning_rate": 1.1601731601731602e-05,
      "loss": 0.435,
      "step": 890
    },
    {
      "epoch": 2.32,
      "learning_rate": 1.1515151515151517e-05,
      "loss": 0.4225,
      "step": 892
    },
    {
      "epoch": 2.32,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.4163,
      "step": 894
    },
    {
      "epoch": 2.33,
      "learning_rate": 1.1341991341991343e-05,
      "loss": 0.4351,
      "step": 896
    },
    {
      "epoch": 2.33,
      "learning_rate": 1.1255411255411256e-05,
      "loss": 0.548,
      "step": 898
    },
    {
      "epoch": 2.34,
      "learning_rate": 1.1168831168831168e-05,
      "loss": 0.532,
      "step": 900
    },
    {
      "epoch": 2.34,
      "learning_rate": 1.1082251082251083e-05,
      "loss": 0.44,
      "step": 902
    },
    {
      "epoch": 2.35,
      "learning_rate": 1.0995670995670997e-05,
      "loss": 0.4939,
      "step": 904
    },
    {
      "epoch": 2.35,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.4682,
      "step": 906
    },
    {
      "epoch": 2.36,
      "learning_rate": 1.0822510822510823e-05,
      "loss": 0.6428,
      "step": 908
    },
    {
      "epoch": 2.36,
      "learning_rate": 1.0735930735930736e-05,
      "loss": 0.4833,
      "step": 910
    },
    {
      "epoch": 2.37,
      "learning_rate": 1.064935064935065e-05,
      "loss": 0.4859,
      "step": 912
    },
    {
      "epoch": 2.37,
      "learning_rate": 1.0562770562770563e-05,
      "loss": 0.5869,
      "step": 914
    },
    {
      "epoch": 2.38,
      "learning_rate": 1.0476190476190477e-05,
      "loss": 0.5494,
      "step": 916
    },
    {
      "epoch": 2.38,
      "learning_rate": 1.038961038961039e-05,
      "loss": 0.4514,
      "step": 918
    },
    {
      "epoch": 2.39,
      "learning_rate": 1.0303030303030304e-05,
      "loss": 0.4418,
      "step": 920
    },
    {
      "epoch": 2.39,
      "learning_rate": 1.0216450216450218e-05,
      "loss": 0.416,
      "step": 922
    },
    {
      "epoch": 2.4,
      "learning_rate": 1.0129870129870131e-05,
      "loss": 0.5009,
      "step": 924
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.0043290043290043e-05,
      "loss": 0.5174,
      "step": 926
    },
    {
      "epoch": 2.41,
      "learning_rate": 9.956709956709957e-06,
      "loss": 0.496,
      "step": 928
    },
    {
      "epoch": 2.42,
      "learning_rate": 9.87012987012987e-06,
      "loss": 0.4187,
      "step": 930
    },
    {
      "epoch": 2.42,
      "learning_rate": 9.783549783549784e-06,
      "loss": 0.4672,
      "step": 932
    },
    {
      "epoch": 2.43,
      "learning_rate": 9.696969696969698e-06,
      "loss": 0.4718,
      "step": 934
    },
    {
      "epoch": 2.43,
      "learning_rate": 9.610389610389611e-06,
      "loss": 0.5649,
      "step": 936
    },
    {
      "epoch": 2.44,
      "learning_rate": 9.523809523809523e-06,
      "loss": 0.5548,
      "step": 938
    },
    {
      "epoch": 2.44,
      "learning_rate": 9.437229437229438e-06,
      "loss": 0.4348,
      "step": 940
    },
    {
      "epoch": 2.45,
      "learning_rate": 9.350649350649352e-06,
      "loss": 0.4241,
      "step": 942
    },
    {
      "epoch": 2.45,
      "learning_rate": 9.264069264069264e-06,
      "loss": 0.3937,
      "step": 944
    },
    {
      "epoch": 2.46,
      "learning_rate": 9.177489177489177e-06,
      "loss": 0.4134,
      "step": 946
    },
    {
      "epoch": 2.46,
      "learning_rate": 9.090909090909091e-06,
      "loss": 0.4234,
      "step": 948
    },
    {
      "epoch": 2.47,
      "learning_rate": 9.004329004329005e-06,
      "loss": 0.3508,
      "step": 950
    },
    {
      "epoch": 2.47,
      "learning_rate": 8.917748917748918e-06,
      "loss": 0.4564,
      "step": 952
    },
    {
      "epoch": 2.48,
      "learning_rate": 8.831168831168832e-06,
      "loss": 0.4053,
      "step": 954
    },
    {
      "epoch": 2.48,
      "learning_rate": 8.744588744588745e-06,
      "loss": 0.4548,
      "step": 956
    },
    {
      "epoch": 2.49,
      "learning_rate": 8.658008658008657e-06,
      "loss": 0.442,
      "step": 958
    },
    {
      "epoch": 2.49,
      "learning_rate": 8.571428571428573e-06,
      "loss": 0.4593,
      "step": 960
    },
    {
      "epoch": 2.5,
      "learning_rate": 8.484848484848486e-06,
      "loss": 0.4232,
      "step": 962
    },
    {
      "epoch": 2.5,
      "learning_rate": 8.398268398268398e-06,
      "loss": 0.4727,
      "step": 964
    },
    {
      "epoch": 2.51,
      "learning_rate": 8.311688311688312e-06,
      "loss": 0.4027,
      "step": 966
    },
    {
      "epoch": 2.51,
      "learning_rate": 8.225108225108225e-06,
      "loss": 0.4548,
      "step": 968
    },
    {
      "epoch": 2.52,
      "learning_rate": 8.138528138528139e-06,
      "loss": 0.4543,
      "step": 970
    },
    {
      "epoch": 2.52,
      "learning_rate": 8.051948051948052e-06,
      "loss": 0.4243,
      "step": 972
    },
    {
      "epoch": 2.53,
      "learning_rate": 7.965367965367966e-06,
      "loss": 0.3761,
      "step": 974
    },
    {
      "epoch": 2.54,
      "learning_rate": 7.878787878787878e-06,
      "loss": 0.3882,
      "step": 976
    },
    {
      "epoch": 2.54,
      "learning_rate": 7.792207792207792e-06,
      "loss": 0.3851,
      "step": 978
    },
    {
      "epoch": 2.55,
      "learning_rate": 7.705627705627707e-06,
      "loss": 0.4479,
      "step": 980
    },
    {
      "epoch": 2.55,
      "learning_rate": 7.6190476190476205e-06,
      "loss": 0.428,
      "step": 982
    },
    {
      "epoch": 2.56,
      "learning_rate": 7.532467532467532e-06,
      "loss": 0.4539,
      "step": 984
    },
    {
      "epoch": 2.56,
      "learning_rate": 7.445887445887447e-06,
      "loss": 0.5046,
      "step": 986
    },
    {
      "epoch": 2.57,
      "learning_rate": 7.35930735930736e-06,
      "loss": 0.4368,
      "step": 988
    },
    {
      "epoch": 2.57,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.5084,
      "step": 990
    },
    {
      "epoch": 2.58,
      "learning_rate": 7.186147186147187e-06,
      "loss": 0.4239,
      "step": 992
    },
    {
      "epoch": 2.58,
      "learning_rate": 7.0995670995671e-06,
      "loss": 0.4048,
      "step": 994
    },
    {
      "epoch": 2.59,
      "learning_rate": 7.012987012987013e-06,
      "loss": 0.4392,
      "step": 996
    },
    {
      "epoch": 2.59,
      "learning_rate": 6.926406926406927e-06,
      "loss": 0.5226,
      "step": 998
    },
    {
      "epoch": 2.6,
      "learning_rate": 6.83982683982684e-06,
      "loss": 0.5079,
      "step": 1000
    },
    {
      "epoch": 2.6,
      "eval_cer": 0.013937282229965157,
      "eval_loss": 0.5579602718353271,
      "eval_runtime": 104.6031,
      "eval_samples_per_second": 7.361,
      "eval_steps_per_second": 0.927,
      "step": 1000
    }
  ],
  "max_steps": 1155,
  "num_train_epochs": 3,
  "total_flos": 7.07739381438559e+18,
  "trial_name": null,
  "trial_params": null
}
